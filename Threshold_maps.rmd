---
title: "OSPAR Assessment Steps for UK ESG"
author: "Kate Collingridge, Liam Fernand and Michelle Devlin"
date: "22/02/2022"
output: html_document
---

```{r setup, include=FALSE}
library(leaflet)
library(sf)
library(viridis)
library(leafsync)
library(rgdal)
library(knitr)
library(raster)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

This document presents the new proposed methods for the COMP4 OSPAR eutrophication assessment, including thresholds for UK assessment areas for consideration by the Eutrophication Steering Group. For more detail on how the thresholds and assessment areas were developed see the ICG-EMO report and OSPAR COMP Annexes (3 and 7).

# COMP3

### COMP3 Assessment Areas

For COMP3 there were 8 assessment areas, as in Charting Progress 2. Each country used their own assessment areas with no alignment
[comment]: # (is it worth putting the other countries' assessment areas on the map too?)


```{r old assessement areas}
#Map
COMP3_areas <- readOGR(dsn = "Shapefiles", layer = "CP2_WGS84", verbose = F)
leaflet(COMP3_areas) %>%
  addTiles() %>%
  addPolygons(color = "black", fillOpacity = 0, weight = 1, label = paste0("Region ", COMP3_areas$CP2_Region)) %>% 
  setView(-0,55,zoom = 5)


```
### COMP3 Thresholds

For the previous UK comprehensive eutrophication assessment (COMP3) thresholds were the same for all assessment areas and only dependent on salinity with a different threshold for "coastal" and "offshore" waters.
[comment]: # (Maybe add something about the assessment statistics too?)



```{r old thresholds}
#old assessment thresholds.

thres_COMP3 <- data.frame(Variable = c("DIN", "CPHL", "DOXY"),
                          Coastal_threshold = c(18, 15, 6),
                          Offshore_threshold  = c(15, 10, 6),
                          Metric = c("Mean", "90th percentile", "Mean of lowest quartile in bottom waters"))
kable(thres_COMP3)
```


[comment]: # (should we include the results of the previous assessment here?? And that it was a simple pass/fail with confidence assessment)


# COMP4

Between the COMP3 and anticipated COMP4 assessments there have been many developments to make the assessments more scientifically robust, ecologically relevant and coherent between countries. These developments started in the EUNOSAT project focussed on the North Sea and have been further developed in OSPAR through ICG-EMO and TG-COMP.

## New Assessment areas

During the EUNOSAT project new "ecologically coherent" assessment areas were developed (more detail, or just ref eunosat report). These have been further modified since the project completion to include additional assessment areas in places not covered during the EUNOSAT project, and to remove overlap with WFD areas.


```{r assessment areas}
COMP4_areas <- sf::st_read("https://raw.githubusercontent.com/ices-tools-prod/COMPEAT/master/assessment_areas/COMP4_assessment_areas.csv",quiet = T) %>%
  st_set_crs(4326)
#COMP4_areas <- sf::st_read("assessment_areas/COMP4_assessment_areas.csv") %>%
  st_set_crs(4326)
#Map of new assessment areas
leaflet(COMP4_areas) %>%
  addTiles() %>%
  addPolygons(color = "black", fillOpacity = 0, weight = 1, label = ~COMP4_areas$ID, popup = COMP4_areas$Area_Name_) %>% # popups not quite working properly
  setView(-0,55,zoom = 5)

#include more detailed map of plume areas explaining how WFD areas were incorporated.

```

Additionally some river plume assessment areas were added. For the UK this includes the Thames, the Humber and Liverpool Bay.
Plumes were delineated using SPM contours from a 10 year average of remote sensing data. For the Thames and Liverpool Bay some outer WFD assessment areas were included in the plume polygon.

```{r plumes, eval = F}

wfd <- readOGR(dsn = "Shapefiles", layer = "WFD_UK", verbose = F)
wfd <- spTransform(wfd, CRS("+init=epsg:4326"))

#livbay

livbay_wfd <- raster::crop(wfd, extent(-5, -2.5, 52, 55))

COMP4_areas <- sf:::as_Spatial(st_zm(COMP4_areas))

livbay <- leaflet(COMP4_areas) %>%
  addTiles() %>%
  addPolygons(color = "black", fillOpacity = 0, weight = 1, highlight = highlightOptions(weight = 3, bringToFront = TRUE, sendToBack = TRUE)) %>%
  addPolygons(data = livbay_wfd, color = "green", fillOpacity = 0, weight = 1, label = paste0(wfd$WB_NAME, ";   Adjacent COMP4 assessment area: ", wfd$COMP4_area), highlight = highlightOptions(weight = 3, bringToFront = TRUE, sendToBack = TRUE)) %>% 
  fitBounds(lng1 = bbox(subset(COMP4_areas, ID == "LBPM"))[1], lat1 = bbox(subset(COMP4_areas, ID == "LBPM"))[2], lng2 = bbox(subset(COMP4_areas, ID == "LBPM"))[3], lat2 = bbox(subset(COMP4_areas, ID == "LBPM"))[4])


#thames
thames_wfd <-crop(wfd, extent(0, 3, 51, 53))

thames <- leaflet(COMP4_areas) %>%
  addTiles() %>%
  addPolygons(color = "black", fillOpacity = 0, weight = 1, highlight = highlightOptions(weight = 3, bringToFront = TRUE, sendToBack = TRUE)) %>%
  addPolygons(data = thames_wfd, color = "green", fillOpacity = 0, weight = 1, label = paste0(wfd$WB_NAME, ";   Adjacent COMP4 assessment area: ", wfd$COMP4_area), highlight = highlightOptions(weight = 3, bringToFront = TRUE, sendToBack = TRUE)) %>% 
  fitBounds(lng1 = bbox(subset(COMP4_areas, ID == "THPM"))[1], lat1 = bbox(subset(COMP4_areas, ID == "THPM"))[2], lng2 = bbox(subset(COMP4_areas, ID == "THPM"))[3], lat2 = bbox(subset(COMP4_areas, ID == "THPM"))[4])


#humber
humber_wfd <-crop(wfd, extent(-1, 2, 52.5, 54.5))

humber <- leaflet(COMP4_areas) %>%
  addTiles() %>%
  addPolygons(color = "black", fillOpacity = 0, weight = 1, label = COMP4_areas$Area_Name_, highlight = highlightOptions(weight = 3, bringToFront = TRUE, sendToBack = TRUE)) %>%
  addPolygons(data = humber_wfd, color = "green", fillOpacity = 0, weight = 1, label = paste0(wfd$WB_NAME, ";   Adjacent COMP4 assessment area: ", wfd$COMP4_area), highlight = highlightOptions(weight = 3, bringToFront = TRUE, sendToBack = TRUE)) %>% 
  fitBounds(lng1 = bbox(subset(COMP4_areas, ID == "HPM"))[1], lat1 = bbox(subset(COMP4_areas, ID == "HPM"))[2], lng2 = bbox(subset(COMP4_areas, ID == "HPM"))[3], lat2 = bbox(subset(COMP4_areas, ID == "HPM"))[4])

thames
humber
livbay
#latticeview(thames, humber, livbay, ncol = 3, sync.cursor = F) # figure out if it is possible to add space between them
```



## New Assessment thresholds

### Eunosat

During the eunosat project a different approach for determining thresholds was developed. "Reference conditions" for nutrients and chlorophyll were modelled for the year 1900 and 50% was added to these to form the assessment thresholds for nutrients and chlorophyll. This was based on xxx model at Deltares.

[comment]: # (could add a map here but might be better just to skip to the later versions)


## ICG-EMO

The work on thresholds has been further developed by ICG-EMO, using x models.... Liam to expand.

Assessment thresholds were averaged for each assessment area.

HS1 and HS2 scenarios

Relative method

```{r new thresholds}
#Thresholds

thres <- read.table("C:/Users/KC05/OneDrive - CEFAS/Shiny_apps/COMP_data/COMP_data_shiny/data/Thresholds_ICGEMO_Jan2022.csv", header = T, sep = ",") # these are the HS1 thresholds

#merge thresholds onto COMP4_areas

COMP4_areas <- merge(COMP4_areas,thres,by="ID")
#COMP4_areas <- sf:::as_Spatial(st_zm(COMP4_areas))

#Chl - might want to show 90th percentile too?

pal <- colorNumeric(palette = viridis(255), domain = c(0,20), na.color = "#00000000")
m1 <- leaflet(COMP4_areas) %>%
  addTiles() %>%
  addPolygons(fillColor = ~pal(Chla) ,color = "black", fillOpacity = 1, weight = 1, popup = paste0(COMP4_areas$Area_Name_, "<br>","Chlorophyll", " theshold: ", as.character(round(COMP4_areas$Chla,2)), " (HS1).")) %>%
  addLegend(pal = pal, values = c(0,20), title = "Chlorophyll (ug/l)") %>%
  setView(3,54, zoom = 4)

#DIN

pal <- colorNumeric(palette = viridis(255), domain = c(0,30), na.color = "#00000000")
m2 <- leaflet(COMP4_areas) %>%
  addTiles() %>%
  addPolygons(fillColor = ~pal(DIN) ,color = "black", fillOpacity = 1, weight = 1, popup = paste0(COMP4_areas$Area_Name_, "<br>","Chlorophyll", " theshold: ", as.character(round(COMP4_areas$DIN,2)), " (HS1)")) %>%
  addLegend(pal = pal, values = c(0,30), title = "DIN (uM)") %>%
  setView(3,54, zoom = 4)

#DIP

pal <- colorNumeric(palette = viridis(255), domain = c(0,3), na.color = "#00000000")
m3 <- leaflet(COMP4_areas) %>%
  addTiles() %>%
  addPolygons(fillColor = ~pal(DIP) ,color = "black", fillOpacity = 1, weight = 1, popup = paste0(COMP4_areas$Area_Name_, "<br>","Chlorophyll", " theshold: ", as.character(round(COMP4_areas$DIP,2)), " (HS1)")) %>%
  addLegend(pal = pal, values = c(0,3), title = "DIP (uM)") %>%
  setView(3,54, zoom = 4)
sync(m1, m2, m3, ncol = 3, sync.cursor = F)

#Doxy - Don't need map, it is 6 mg/l everywhere.

```

Any points of discussion.
Comparison of old and new thresholds - show assessment areas where they go up and down.
```{r salinity, eval = F}

#Calculate average and min/max salinity of each assessment area to know whether to assign it coastal or offshore for old thresholds, then calculate difference between old and new thresholds and plot on map.

sal <- raster("Z:/Eutrophication/EUNOSAT/project_output/newmodelresultsfromanouk_nov19/sal.tif")


#sal_mean <- extract(sal, COMP4_areas, fun = mean, df = TRUE, na.rm = TRUE)
#save(sal_mean, file = "Shapefiles/sal_mean.rdata")
load("Shapefiles/sal_mean.rdata")

#sal_std <- extract(sal, COMP4_areas, fun = sd, df = TRUE, na.rm = TRUE)
#save(sal_std, file = "Shapefiles/sal_std.rdata")
load("Shapefiles/sal_std.rdata")

#sal_10pc <- extract(sal, COMP4_areas, fun = function(x,...){quantile(x, 0.1,na.rm = TRUE)}, df = TRUE, na.rm = TRUE)
#save(sal_10pc, file = "Shapefiles/sal_10pc.rdata")
load("Shapefiles/sal_10pc.rdata")

#sal_90pc <- extract(sal, COMP4_areas, fun = function(x,...){quantile(x, 0.9,na.rm = TRUE)}, df = TRUE, na.rm = TRUE)
#save(sal_90pc, file = "Shapefiles/sal_90pc.rdata")
load("Shapefiles/sal_90pc.rdata")

sal <- cbind(COMP4_areas$ID, sal_mean[2], sal_std[2], sal_10pc[2], sal_90pc[2])
colnames(sal) <- c("ID", "sal_mean", "sal_std", "sal_10pc", "sal_90pc")
sal <- sal[!is.na(sal$sal_mean),]
sal$CO <- NA
#Setting coastal and offshore for those areas that are entirely in one category based on salinity extremes (10th and 90th percentiles)
sal[sal$sal_90pc<34.5 & sal$ID != "IRS" & sal$ID != "LBPM",]$CO <- "coastal"
sal[sal$sal_10pc>34.5 & sal$ID != "IRS" & sal$ID != "LBPM",]$CO <- "offshore"

sal[sal$sal_90pc<34 & sal$ID == "IRS" | sal$ID == "LBPM",]$CO <- "coastal"
sal[sal$sal_10pc>34 & sal$ID == "IRS" | sal$ID == "LBPM",]$CO <- "offshore"

sal$classification <- NA

sal[is.na(sal$CO),]$classification <- "Salinity varies between 'coastal' and 'offshore'"


#Setting coastal and offshore for those areas that are overlap categories based on salinity means 

sal[sal$sal_mean<34.5 & sal$ID != "IRS" & is.na(sal$CO),]$CO <- "coastal"
sal[sal$sal_mean>34.5 & sal$ID != "IRS" & is.na(sal$CO),]$CO <- "offshore"

sal[sal$sal_mean<34 & sal$ID == "IRS" & is.na(sal$CO),]$CO <- "coastal"
sal[sal$sal_mean>34  & sal$ID == "IRS" & is.na(sal$CO),]$CO <- "offshore" # error because already flagged as coastal


#Add COMP3 thresholds

sal$COMP3_DIN <- NA
sal$COMP3_CPHL <- NA
sal$COMP3_DO <- NA

sal[sal$CO == "coastal",]$COMP3_DIN <- thres_COMP3[thres_COMP3$Variable == "DIN",]$Coastal_threshold
sal[sal$CO == "offshore",]$COMP3_DIN <- thres_COMP3[thres_COMP3$Variable == "DIN",]$Offshore_threshold

sal[sal$CO == "coastal",]$COMP3_CPHL <- thres_COMP3[thres_COMP3$Variable == "CPHL",]$Coastal_threshold
sal[sal$CO == "offshore",]$COMP3_CPHL <- thres_COMP3[thres_COMP3$Variable == "CPHL",]$Offshore_threshold

sal[sal$CO == "coastal",]$COMP3_DO <- thres_COMP3[thres_COMP3$Variable == "DOXY",]$Coastal_threshold
sal[sal$CO == "offshore",]$COMP3_DO <- thres_COMP3[thres_COMP3$Variable == "DOXY",]$Offshore_threshold

COMP4_areas_COMP3_thres <- sal[,c(1,6:10)]

```
## WFD thresholds

Below is a map of WFD areas showing which COMP4 area(s) they align with.

[comment]: # (add the actual WFD thresholds when I have them.)


```{r wfd}
wfd <- readOGR(dsn = "Shapefiles", layer = "WFD_UK", verbose = F)
wfd <- spTransform(wfd, CRS("+init=epsg:4326"))
leaflet(wfd) %>%
  addTiles() %>%
  addPolygons(color = "green", fillOpacity = 0, weight = 1, label = paste0(wfd$WB_NAME, ";   Adjacent COMP4 assessment area: ", wfd$COMP4_area)) %>% 
  addPolygons(data = COMP4_areas, color = "black", fillOpacity = 0, weight = 1, label = paste0(COMP4_areas$ID, " - ", COMP4_areas$Area_Name_)) %>%
  setView(-0,55,zoom = 5)

```

## EQRS

Flow chart explaining EQRS

## Confidence

Section on confidence ratings

## Data

Perhaps for another document, include map of all data currently included in the assessment

## Assessment results?
