---
title: "OSPAR Assessment Steps for UK ESG"
author: "Kate Collingridge, Liam Fernand and Michelle Devlin"
date: "22/02/2022"
output: html_document
---

```{r setup, include=FALSE}
library(leaflet)
library(sf)
library(viridis)
library(leafsync)
library(rgdal)
library(knitr)
library(raster)
library(cmocean)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
```

This is a summary of the process for delivery of the  fourth OSPAR assessment for the eutrophication status of the OSPAR Maritime Area under the Common Procedure for the Identification of the eutrophication status of the OSPAR Maritime Area (the “Common Procedure”) (OSPAR, 2022). It follows and builds on the results of the previous applications of the Comprehensive Procedure (OSPAR, 2003a, 2008, 2017).  It is a summary of the approach, the changes that have occurred since the third OSPAR assessment, particularly in relation to UK marine waters. 

The purpose of the assessment is:

<li>to assess the eutrophication status of the OSPAR Maritime Area and its Regions based on data for the period 2015–2019(2020?); </li>
<li>to evaluate progress made towards achieving the objectives of the OSPAR Eutrophication Strategy; </li>
<li>to consider the effectiveness of measures taken to combat eutrophication on the state of the marine environment, and; </li>
<li>to identify priorities for future actions. </li>


The application of the Common Procedure differs from earlier reports as this is the first time it has been applied using a harmonised assessment tool, COMPEAT. This applies the Common Procedure in a uniform, semi-automated way across the OSPAR Convention Area, removing the need for national eutrophication reports.

OSPAR’s North East Atlantic Environment Strategy (OSPAR, 2021) takes forward work related to the implementation of the Ecosystem Approach and the suite of five thematic strategies, to address the main threats that it has identified concerning issues within its competence. The aim of the OSPAR Eutrophication Strategy is to make every effort to combat eutrophication in the OSPAR Maritime Area in order to achieve and maintain, by 2020, a healthy marine environment where eutrophication does not occur. 
 
The OSPAR Maritime Area covers most of the North-East Atlantic. It embraces open sea areas as well as inshore and coastal waters adjacent to densely populated catchments where pressures from human activities are particularly high


# Common Procedure

The Common Procedure makes use of the OSPAR Common Indicators (Winter nutrient concentrations; Concentrations of chlorophyll-a; and Concentrations of Dissolved Oxygen Near the Seafloor) and applies a common assessment tool (COMPEAT) in order to produce an assessment of eutrophication status for each assessment area within the entire OSPAR Convention area.

OSPAR eutrophication data are collected through the Joint Assessment and Monitoring Programme and reported annually to ICES, which is responsible for the management and storage of the data. The COMPEAT tool extracts relevant eutrophication data from the ICES databases and assesses eutrophication criteria against agreed threshold levels in ecologically relevant assessment units. Data collected outside of the JAMP (Joint Assessment Monitoring Programme), or assessed for example under the Water Framework Directive (WFD), can be included in the assessment system. The assessment results are reported in terms of an Ecological Quality Ratios (EQRs) which allows the relative distance to Non-problem status to be visualised. Trends in EQRs can provide estimates of the time needed before Non-problem status is reached, on the assumption that measures continue to be implemented. 


# COMP3

### COMP3 Assessment Areas

For COMP3 there were 8 assessment areas, as in Charting Progress 2. Each country used their own assessment areas with no alignment
[comment]: # (is it worth putting the other countries' assessment areas on the map too?)


```{r old assessement areas}
#Map
COMP3_areas <- readOGR(dsn = "Shapefiles", layer = "CP2_WGS84", verbose = F)
leaflet(COMP3_areas) %>%
  addTiles() %>%
  addPolygons(color = "black", fillOpacity = 0, weight = 1, label = paste0("Region ", COMP3_areas$CP2_Region)) %>% 
  setView(-0,55,zoom = 5)


```
### COMP3 Thresholds

For the previous UK comprehensive eutrophication assessment (COMP3) thresholds were the same for all assessment areas and only dependent on salinity with a different threshold for "coastal" and "offshore" waters.
[comment]: # (Maybe add something about the assessment statistics too?)



```{r old thresholds}
#old assessment thresholds.

thres_COMP3 <- data.frame(Variable = c("DIN", "CPHL", "DOXY"),
                          Coastal_threshold = c(18, 15, 6),
                          Offshore_threshold  = c(15, 10, 6),
                          Metric = c("Mean", "90th percentile", "Mean of lowest quartile in bottom waters"))
kable(thres_COMP3)

```


[comment]: # (should we include the results of the previous assessment here?? And that it was a simple pass/fail with confidence assessment)


# COMP4

Between the COMP3 and anticipated COMP4 assessments there have been many developments to make the assessments more scientifically robust, ecologically relevant and coherent between countries. These developments started in the EUNOSAT project focussed on the North Sea and have been further developed in OSPAR through ICG-EMO and TG-COMP.

## New Assessment areas

During the EUNOSAT project new "ecologically coherent" assessment areas were developed (more detail, or just ref eunosat report). These have been further modified since the project completion to include additional assessment areas in places not covered during the EUNOSAT project, and to remove overlap with WFD areas.


```{r assessment areas}
COMP4_areas <- sf::st_read("https://raw.githubusercontent.com/ices-tools-prod/COMPEAT/master/assessment_areas/COMP4_assessment_areas.csv",quiet = T) %>%
  st_set_crs(4326)
#COMP4_areas <- sf::st_read("assessment_areas/COMP4_assessment_areas.csv") %>% st_set_crs(4326)
#Map of new assessment areas
leaflet(COMP4_areas) %>%
  addTiles() %>%
  addPolygons(color = "black", fillOpacity = 0, weight = 1, label = ~COMP4_areas$ID, popup = COMP4_areas$Area_Name_) %>% # popups not quite working properly
  setView(-0,55,zoom = 5)

#include more detailed map of plume areas explaining how WFD areas were incorporated.

```

Additionally some river plume assessment areas were added. For the UK this includes the Thames, the Humber and Liverpool Bay.
Plumes were delineated using SPM contours from a 10 year average of remote sensing data. For the Thames and Liverpool Bay some outer WFD assessment areas were included in the plume polygon.

```{r plumes, eval = F}

wfd <- readOGR(dsn = "Shapefiles", layer = "WFD_UK", verbose = F)
wfd <- spTransform(wfd, CRS("+init=epsg:4326"))

#livbay

livbay_wfd <- raster::crop(wfd, extent(-5, -2.5, 52, 55))

COMP4_areas <- sf:::as_Spatial(st_zm(COMP4_areas))

livbay <- leaflet(COMP4_areas) %>%
  addTiles() %>%
  addPolygons(color = "black", fillOpacity = 0, weight = 1, highlight = highlightOptions(weight = 3, bringToFront = TRUE, sendToBack = TRUE)) %>%
  addPolygons(data = livbay_wfd, color = "green", fillOpacity = 0, weight = 1, label = paste0(wfd$WB_NAME, ";   Adjacent COMP4 assessment area: ", wfd$COMP4_area), highlight = highlightOptions(weight = 3, bringToFront = TRUE, sendToBack = TRUE)) %>% 
  fitBounds(lng1 = bbox(subset(COMP4_areas, ID == "LBPM"))[1], lat1 = bbox(subset(COMP4_areas, ID == "LBPM"))[2], lng2 = bbox(subset(COMP4_areas, ID == "LBPM"))[3], lat2 = bbox(subset(COMP4_areas, ID == "LBPM"))[4])


#thames
thames_wfd <-crop(wfd, extent(0, 3, 51, 53))

thames <- leaflet(COMP4_areas) %>%
  addTiles() %>%
  addPolygons(color = "black", fillOpacity = 0, weight = 1, highlight = highlightOptions(weight = 3, bringToFront = TRUE, sendToBack = TRUE)) %>%
  addPolygons(data = thames_wfd, color = "green", fillOpacity = 0, weight = 1, label = paste0(wfd$WB_NAME, ";   Adjacent COMP4 assessment area: ", wfd$COMP4_area), highlight = highlightOptions(weight = 3, bringToFront = TRUE, sendToBack = TRUE)) %>% 
  fitBounds(lng1 = bbox(subset(COMP4_areas, ID == "THPM"))[1], lat1 = bbox(subset(COMP4_areas, ID == "THPM"))[2], lng2 = bbox(subset(COMP4_areas, ID == "THPM"))[3], lat2 = bbox(subset(COMP4_areas, ID == "THPM"))[4])


#humber
humber_wfd <-crop(wfd, extent(-1, 2, 52.5, 54.5))

humber <- leaflet(COMP4_areas) %>%
  addTiles() %>%
  addPolygons(color = "black", fillOpacity = 0, weight = 1, label = COMP4_areas$Area_Name_, highlight = highlightOptions(weight = 3, bringToFront = TRUE, sendToBack = TRUE)) %>%
  addPolygons(data = humber_wfd, color = "green", fillOpacity = 0, weight = 1, label = paste0(wfd$WB_NAME, ";   Adjacent COMP4 assessment area: ", wfd$COMP4_area), highlight = highlightOptions(weight = 3, bringToFront = TRUE, sendToBack = TRUE)) %>% 
  fitBounds(lng1 = bbox(subset(COMP4_areas, ID == "HPM"))[1], lat1 = bbox(subset(COMP4_areas, ID == "HPM"))[2], lng2 = bbox(subset(COMP4_areas, ID == "HPM"))[3], lat2 = bbox(subset(COMP4_areas, ID == "HPM"))[4])

thames
humber
livbay
#latticeview(thames, humber, livbay, ncol = 3, sync.cursor = F) # figure out if it is possible to add space between them
```



## New Assessment thresholds

### Ehype/Eunosat

During the eunosat project a different approach for determining thresholds was developed. THe E-hype project produced estimates of the DIN and DIP discharge for the major European rivers for the year 1900 corresponding to a pre industrialisation of production of condition. These were used to model "Reference conditions" for nutrients and chlorophyll for the year 1900 using E-hype inputs and 50% was added to these to form the assessment thresholds for nutrients and chlorophyll. This was based on xxx model at Deltares.

[comment]: # (could add a map here but might be better just to skip to the later versions)


## ICG-EMO

The work on thresholds has been further developed by ICG-EMO. 
It has the following specific steps.

<ol>

<li>The e-hype riverine conditions for 1900 were used with two scenarios (HS1 and HS2). Each country looked at the scenarios for their country and checked if they were broadly in agreement.  Germany identified an additional scenario (HS2) which varied the DIP for Dutch, German and Danish Waters, but does not affect UK waters.</li>

<li>Multiple models were run for the HS1 and HS2 scenarios for 1900</li>

<li>The models were also run for a Current Status (CS) period 2009 -2014. Model information was extracted at the assessment unit scale.</li>

<li>For each assessment unit, the CS period runs for the models were compared with <em>in situ</em> observations and the satellite chlorophyll product from COMPEAT. It used the output from COMPEAT at the assessment unit scale.

This produces a weighting factor where models that represent the observations well contribute more highly than those which represent the observations poorly. This weighting is used to apply to all the models in the historic scenario, to produce a weighted ensemble of the reference condition , for both HS1 and HS2.

The weighted historic scenario model produces the reference value (called BEST in COMPEAT) which defines high status.</li>


<li>The acceptable deviation from the reference is defined as 50%,  this sets the good/moderate threshold boundary. E.g. DIN for Atlantic the reference value (BEST) is 10 uM and the eutrophication threshold is 15 uM.</li>
</ol>

### Relative method

The Relative method is an alternative method for calculating assessment thresholds. It works by using the percentage reduction between the model historic runs and the current status run and then applying that to the observations in the current status run to obtain a reference value. The acceptable deviation is then added to get the eutrophication threshold.  This method is very reliant on having good quality data. 


The maps below present the HS1 thresholds. The UK ESG needs to agree where we can accept these and where they are not acceptable. In these cases we should in the first instance look at the relative method thresholds.



```{r new thresholds}
#Thresholds

thres <- read.table("C:/Users/KC05/OneDrive - CEFAS/Shiny_apps/COMP_data/COMP_data_shiny/data/Thresholds_ICGEMO_Jan2022.csv", header = T, sep = ",") # these are the HS1 thresholds

#merge thresholds onto COMP4_areas

COMP4_areas <- merge(COMP4_areas,thres,by="ID")
#COMP4_areas <- sf:::as_Spatial(st_zm(COMP4_areas))

#Chl - might want to show 90th percentile too?

pal <- colorNumeric(palette = viridis(255), domain = c(0,20), na.color = "#00000000")
m1 <- leaflet(COMP4_areas) %>%
  addTiles() %>%
  addPolygons(fillColor = ~pal(Chla) ,color = "black", fillOpacity = 1, weight = 1, popup = paste0(COMP4_areas$Area_Name_, "<br>","Chlorophyll theshold: ", as.character(round(COMP4_areas$Chla,2)), " (HS1).", "<br>", "(90thpc thres would be ", COMP4_areas$Chla90th, ")")) %>%
  addLegend(pal = pal, values = c(0,20), title = "Chlorophyll (ug/l)") %>%
  setView(3,54, zoom = 4)

#DIN

pal <- colorNumeric(palette = viridis(255), domain = c(0,30), na.color = "#00000000")
m2 <- leaflet(COMP4_areas) %>%
  addTiles() %>%
  addPolygons(fillColor = ~pal(DIN) ,color = "black", fillOpacity = 1, weight = 1, popup = paste0(COMP4_areas$Area_Name_, "<br>","DIN", " theshold: ", as.character(round(COMP4_areas$DIN,2)), " (HS1)")) %>%
  addLegend(pal = pal, values = c(0,30), title = "DIN (uM)") %>%
  setView(3,54, zoom = 4)

#DIP

pal <- colorNumeric(palette = viridis(255), domain = c(0,3), na.color = "#00000000")
m3 <- leaflet(COMP4_areas) %>%
  addTiles() %>%
  addPolygons(fillColor = ~pal(DIP) ,color = "black", fillOpacity = 1, weight = 1, popup = paste0(COMP4_areas$Area_Name_, "<br>","DIP theshold: ", as.character(round(COMP4_areas$DIP,2)), " (HS1)")) %>%
  addLegend(pal = pal, values = c(0,3), title = "DIP (uM)") %>%
  setView(3,54, zoom = 4)

sync(m2, m3, m1, ncol = 3, sync.cursor = F)

#Doxy - Don't need map, it is 6 mg/l everywhere.

```

Any points of discussion. Table of thresholds. Relative method thresholds for plume areas.

The map below shows the thresholds used in COMP3, for comparison. As COMP3 thresholds were based on salinity, the new assessment areas have been classified by salinity to match these and show the appropriate threshold. (think maybe this map not necessary, could be a table, the difference one is more useful)


```{r salinity, eval = F}

#Calculate average and min/max salinity of each assessment area to know whether to assign it coastal or offshore for old thresholds, then calculate difference between old and new thresholds and plot on map.

sal <- raster("Z:/Eutrophication/EUNOSAT/project_output/newmodelresultsfromanouk_nov19/sal.tif")


#sal_mean <- extract(sal, COMP4_areas, fun = mean, df = TRUE, na.rm = TRUE)
#save(sal_mean, file = "Shapefiles/sal_mean.rdata")
load("Shapefiles/sal_mean.rdata")

#sal_std <- extract(sal, COMP4_areas, fun = sd, df = TRUE, na.rm = TRUE)
#save(sal_std, file = "Shapefiles/sal_std.rdata")
load("Shapefiles/sal_std.rdata")

#sal_10pc <- extract(sal, COMP4_areas, fun = function(x,...){quantile(x, 0.1,na.rm = TRUE)}, df = TRUE, na.rm = TRUE)
#save(sal_10pc, file = "Shapefiles/sal_10pc.rdata")
load("Shapefiles/sal_10pc.rdata")

#sal_90pc <- extract(sal, COMP4_areas, fun = function(x,...){quantile(x, 0.9,na.rm = TRUE)}, df = TRUE, na.rm = TRUE)
#save(sal_90pc, file = "Shapefiles/sal_90pc.rdata")
load("Shapefiles/sal_90pc.rdata")

sal <- cbind(COMP4_areas$ID, sal_mean[2], sal_std[2], sal_10pc[2], sal_90pc[2])
colnames(sal) <- c("ID", "sal_mean", "sal_std", "sal_10pc", "sal_90pc")
sal <- sal[!is.na(sal$sal_mean),]
sal$CO <- NA
#Setting coastal and offshore for those areas that are entirely in one category based on salinity extremes (10th and 90th percentiles)
sal[sal$sal_90pc<34.5 & sal$ID != "IRS" & sal$ID != "LBPM",]$CO <- "coastal"
sal[sal$sal_10pc>34.5 & sal$ID != "IRS" & sal$ID != "LBPM",]$CO <- "offshore"

sal[sal$ID == "LBPM",]$CO <- "coastal" # doing this one manually
sal[sal$ID == "IRS" ,]$CO <- "offshore" # doing this one manually

sal$classification <- NA

sal[is.na(sal$CO),]$classification <- "Salinity varies between 'coastal' and 'offshore'"


#Setting coastal and offshore for those areas that are overlap categories based on salinity means 

sal[sal$sal_mean<34.5 & sal$ID != "IRS" & is.na(sal$CO),]$CO <- "coastal"
sal[sal$sal_mean>34.5 & sal$ID != "IRS" & is.na(sal$CO),]$CO <- "offshore"




#Add COMP3 thresholds

sal$COMP3_DIN <- NA
sal$COMP3_CPHL <- NA
sal$COMP3_DO <- NA

sal[sal$CO == "coastal",]$COMP3_DIN <- thres_COMP3[thres_COMP3$Variable == "DIN",]$Coastal_threshold
sal[sal$CO == "offshore",]$COMP3_DIN <- thres_COMP3[thres_COMP3$Variable == "DIN",]$Offshore_threshold

sal[sal$CO == "coastal",]$COMP3_CPHL <- thres_COMP3[thres_COMP3$Variable == "CPHL",]$Coastal_threshold
sal[sal$CO == "offshore",]$COMP3_CPHL <- thres_COMP3[thres_COMP3$Variable == "CPHL",]$Offshore_threshold

sal[sal$CO == "coastal",]$COMP3_DO <- thres_COMP3[thres_COMP3$Variable == "DOXY",]$Coastal_threshold
sal[sal$CO == "offshore",]$COMP3_DO <- thres_COMP3[thres_COMP3$Variable == "DOXY",]$Offshore_threshold

COMP4_areas_COMP3_thres <- sal[,c(1,6:10)]
save(COMP4_areas_COMP3_thres, file = "Shapefiles/COMP4_areas_COMP3_thres.rdata")



```

```{r old thres}
#load("Shapefiles/COMP4_areas_COMP3_thres.rdata")
#write.csv(COMP4_areas_COMP3_thres, "Shapefiles/COMP4_areas_COMP3_thres.csv")
COMP4_areas_COMP3_thres <- read.table("Shapefiles/COMP4_areas_COMP3_thres.csv", sep = ",", header = T)

COMP4_areas_COMP3_thres2 <- merge(COMP4_areas, COMP4_areas_COMP3_thres, all.x = T, by = "ID")

pal <- colorNumeric(palette = viridis(255), domain = c(0,30), na.color = "#00000000")
DIN_map <- leaflet(COMP4_areas_COMP3_thres2) %>%
  addTiles() %>%
  addPolygons(fillColor = ~pal(COMP3_DIN) , color = "black", fillOpacity = 1, weight = 1, label = paste0(COMP4_areas_COMP3_thres2$Area_Name_, ": DIN ", COMP4_areas_COMP3_thres2$COMP3_DIN, " uM")) %>% 
  addLegend(pal = pal, values = c(0,30), title = "DIN (uM)") %>%
  setView(-0,55,zoom = 5)

pal <- colorNumeric(palette = viridis(255), domain = c(0,20), na.color = "#00000000")
CPHL_map <- leaflet(COMP4_areas_COMP3_thres2) %>%
  addTiles() %>%
  addPolygons(fillColor = ~pal(COMP3_CPHL) , color = "black", fillOpacity = 1, weight = 1, label = paste0(COMP4_areas_COMP3_thres2$Area_Name_, ": CPHL ", COMP4_areas_COMP3_thres2$COMP3_CPHL, " ug/l")) %>% 
  addLegend(pal = pal, values = c(0,20), title = "Chlorophyll 90pc (ug/l)") %>%
  setView(-0,55,zoom = 5)

sync(DIN_map, CPHL_map, ncol = 2, sync.cursor = F) # does this need to be two maps or one with multiple layers?? tried this and it doesn't seem to work.


```

The map below shows the difference between old and new thresholds for DIN and Chlorophyll (values above 0 are where the new threshold is higher, below 0 where the old threshold was higher. For DIN both thresholds are for the mean. For chlorophyll the threshold for COMP3 is for the 90th percentile. COMP4 will use the mean but for the purposes of comparison this map shows the 90th percentile from the ICG_EMO work (less trusted results than the mean).

```{r comparison}
COMP4_areas_COMP3_thres2$DINmean_diff <- COMP4_areas_COMP3_thres2$DIN - COMP4_areas_COMP3_thres2$COMP3_DIN

COMP4_areas_COMP3_thres2$CPHL90_diff <- COMP4_areas_COMP3_thres2$Chla90th - COMP4_areas_COMP3_thres2$COMP3_CPHL#I have done this comparison based on the 90th percentile

pal <- colorNumeric(palette = cmocean("curl")(255), domain = c(-15,15), na.color = "#00000000")
 
DINdiff_map <- leaflet(COMP4_areas_COMP3_thres2) %>%
  addTiles() %>%
  addPolygons(fillColor = ~pal(DINmean_diff) , color = "black", fillOpacity = 1, weight = 1, label = paste0(COMP4_areas_COMP3_thres2$Area_Name_, ": New DIN threshold ", (COMP4_areas_COMP3_thres2$DINmean_diff)*(-1), " uM  lower")) %>% 
  addLegend(pal = pal, values = c(-15,15), title = "DIN diff (uM)") %>%
  setView(-0,55,zoom = 5)

pal <- colorNumeric(palette = cmocean("curl")(255), domain = c(-15,15), na.color = "#00000000")
CPHLdiff_map <- leaflet(COMP4_areas_COMP3_thres2) %>%
  addTiles() %>%
  addPolygons(fillColor = ~pal(CPHL90_diff) , color = "black", fillOpacity = 1, weight = 1, label = paste0(COMP4_areas_COMP3_thres2$Area_Name_, ": New CPHL threshold ", (COMP4_areas_COMP3_thres2$CPHL90_diff)*(-1), " ug/l lower")) %>% 
  addLegend(pal = pal, values = c(-15,15), title = "Chlorophyll 90pc diff (ug/l)") %>%
  setView(-0,55,zoom = 5)

sync(DINdiff_map, CPHLdiff_map, ncol = 2, sync.cursor = F) # does this need to be two maps or one with multiple layers?? tried this and it doesn't seem to work.


```

## WFD thresholds

Below is a map of WFD areas showing which COMP4 area(s) they align with.

[comment]: # (add the actual WFD thresholds when I have them.)


```{r wfd}
wfd <- readOGR(dsn = "Shapefiles", layer = "WFD_UK", verbose = F)
wfd <- spTransform(wfd, CRS("+init=epsg:4326"))
leaflet(wfd) %>%
  addTiles() %>%
  addPolygons(color = "green", fillOpacity = 0, weight = 1, label = paste0(wfd$WB_NAME, ";   Adjacent COMP4 assessment area: ", wfd$COMP4_area)) %>% 
  addPolygons(data = COMP4_areas, color = "black", fillOpacity = 0, weight = 1, label = paste0(COMP4_areas$ID, " - ", COMP4_areas$Area_Name_)) %>%
  setView(-0,55,zoom = 5)

```

## EQRS

Flow chart explaining EQRS

## Confidence

cnfidence rating of the individual assessment parameters will be applied to indicate the reliability of the data gained from in-situ monitoring, monitoring using novel observation tools (automated buoys, satellite data) and modelling.  Confidence rating of novel observation tools and modelling is estimated during the processing of these data and provided together with the data products, while the confidence of in-situ data is calculated directly in the COMPEAT tool. The confidence of the different data types is combined to the parameter confidence by using weighted averaging, similar to the agreed procedure for the combination of different data types to obtain the status assessment result of the respective parameter. Confidence of assessment against area-specific assessment levels in terms of the probability of correct classification considering the uncertainty as well as of representativeness of monitoring stations in space and time will be assessed.

## Data

Perhaps for another document, include map of all data currently included in the assessment

## Assessment results?
